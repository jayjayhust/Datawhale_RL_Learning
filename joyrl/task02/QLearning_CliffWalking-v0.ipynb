{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 定义算法\n",
    "QLearning是一种用于强化学习的算法，它可以用于找到一个Markov决策过程(MDP)中的最优行动策略。它的主要思想是:\n",
    "1. 算法使用Q函数来确定状态-行动(state-action)值函数。Q函数定义为:Q(s, a)返回执行行动a在状态s下的最大化期望回报。\n",
    "2. Q函数通过迭代更新，使用新的经验来改进值函数。更新公式为:\n",
    "$$Q(s, a) <= Q(s, a) + alpha * (reward + gamma * max_a' Q(s', a') - Q(s, a))$$ \n",
    "- s和s'分别表示当前状态和下一状态，a和a'表示当前行动和下一行动\n",
    "- alpha是学习率，控制更新的量\n",
    "- reward 是执行行动a在状态s后获得的奖励\n",
    "- gamma是折扣因子，衰减了max_a' Q(s', a')的值\n",
    "3. 根据Q函数选择行动策略。通常使用ε-greedy策略，以概率ε选择随机行动，否则选择Q值最大的行动。\n",
    "4. 通过大量迭代并Decaying ε，QLearning可以收敛到最优策略。\n",
    "QLearning的好处是:\n",
    "1. 可以在不需要环境模型的情况下工作，只需要环境的奖励反馈。\n",
    "2. 可以确保找到最优解，如果探索足够的话。\n",
    "3. 相比 SARSA 算法简单易理解。\n",
    "4. 易于实现，代码量少。\n",
    "\n",
    "## 1.1定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch  # pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "from collections import defaultdict\n",
    "\n",
    "class Qlearning(object):\n",
    "    def __init__(self, cfg):\n",
    "        '''智能体类\n",
    "        Args:\n",
    "            cfg (class): 超参数类\n",
    "        '''\n",
    "        self.n_actions = cfg.n_actions \n",
    "        self.exploration_type = 'e-greedy' # 探索策略如 e-greedy，boltzmann，softmax，ucb 等\n",
    "        self.lr = cfg.lr \n",
    "        self.gamma = cfg.gamma    \n",
    "        self.epsilon = cfg.epsilon_start  \n",
    "        self.epsilon_start = cfg.epsilon_start\n",
    "        self.epsilon_end = cfg.epsilon_end\n",
    "        self.epsilon_decay = cfg.epsilon_decay\n",
    "        self.sample_count = 0\n",
    "        self.Q_table  = defaultdict(lambda: np.zeros(self.n_actions)) # 使用嵌套字典来表示 Q(s,a)，并将指定所有的 Q_table 创建时，Q(s,a) 初始设置为 0\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        ''' 以 e-greedy 策略训练时选择动作 \n",
    "        Args:\n",
    "            state (array): 状态\n",
    "        Returns:\n",
    "            action (int): 动作\n",
    "        ''' \n",
    "        if self.exploration_type == 'e-greedy':\n",
    "            action = self._epsilon_greedy_sample_action(state)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return action\n",
    "    \n",
    "    def predict_action(self,state):\n",
    "        ''' 预测动作\n",
    "        Args:\n",
    "            state (array): 状态\n",
    "        Returns:\n",
    "            action (int): 动作\n",
    "        '''\n",
    "        if self.exploration_type == 'e-greedy':\n",
    "            action = self._epsilon_greedy_predict_action(state)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return action\n",
    "    \n",
    "    def _epsilon_greedy_sample_action(self, state):\n",
    "        ''' \n",
    "        采用 epsilon-greedy 策略进行动作选择 \n",
    "        Args: \n",
    "            state (array): 状态\n",
    "        Returns: \n",
    "            action (int): 动作\n",
    "        ''' \n",
    "        self.sample_count += 1\n",
    "        # epsilon 值需要衰减，衰减方式可以是线性、指数等，以平衡探索和开发\n",
    "        self.epsilon = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * \\\n",
    "            math.exp(-1. * self.sample_count / self.epsilon_decay) \n",
    "        if np.random.uniform(0, 1) > self.epsilon:\n",
    "            action = np.argmax(self.Q_table[str(state)]) # 选择具有最大 Q 值的动作\n",
    "        else:\n",
    "            action = np.random.choice(self.n_actions) # 随机选择一个动作\n",
    "        return action\n",
    "    \n",
    "    def _epsilon_greedy_predict_action(self,state):\n",
    "        ''' \n",
    "        使用 epsilon-greedy 算法进行动作预测。在预测时（一般是对已经训练好的策略进行验证），所以不再需要进行探索\n",
    "        Args: \n",
    "            state (array): 状态\n",
    "        Returns: \n",
    "            action (int): 动作 \n",
    "        ''' \n",
    "        action = np.argmax(self.Q_table[str(state)])\n",
    "        return action\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        ''' 更新模型\n",
    "        Args:\n",
    "            state (array): 当前状态 \n",
    "            action (int): 当前动作 \n",
    "            reward (float): 当前奖励信号 \n",
    "            next_state (array): 下一个状态 \n",
    "            done (bool): 表示是否达到终止状态 \n",
    "        '''\n",
    "        Q_predict = self.Q_table[str(state)][action] \n",
    "        if done: # 终止状态 \n",
    "            Q_target = reward  \n",
    "        else:\n",
    "            Q_target = reward + self.gamma * np.max(self.Q_table[str(next_state)]) \n",
    "        self.Q_table[str(state)][action] += self.lr * (Q_target - Q_predict)\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        '''\n",
    "        保存模型\n",
    "        Args:\n",
    "            path (str): 模型存储路径 \n",
    "        '''\n",
    "        import dill\n",
    "        from pathlib import Path\n",
    "        # 确保存储路径存在 \n",
    "        Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(\n",
    "            obj = self.Q_table,\n",
    "            f = path + \"Qleaning_model.pkl\",\n",
    "            pickle_module = dill\n",
    "        )\n",
    "        print(\"Model saved!\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        '''\n",
    "        根据模型路径导入模型\n",
    "        Args:\n",
    "            fpath (str): 模型路径\n",
    "        '''\n",
    "        import dill\n",
    "        self.Q_table = torch.load(f=path + 'Qleaning_model.pkl', pickle_module=dill)\n",
    "        print(\"Mode loaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2定义模型训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, env, agent):\n",
    "    ''' 训练\n",
    "    '''\n",
    "    print(\"开始训练！\")\n",
    "    rewards = []  # 记录所有回合的奖励\n",
    "    steps = []\n",
    "\n",
    "    for i_ep in range(cfg.train_eps):\n",
    "        ep_reward = 0  # 一轮的累计奖励 \n",
    "        ep_step = 0\n",
    "        state = env.reset(seed = cfg.seed)  # 重置环境并获取初始状态\n",
    "        for _ in range(cfg.max_steps):\n",
    "            ep_step += 1\n",
    "            action = agent.sample_action(state)  # 采样动作 \n",
    "            if cfg.new_step_api:\n",
    "                next_state, reward, terminated, truncated , info = env.step(action)  # 更新环境并返回新状态、奖励、终止状态、截断标志和其他信息（使用 OpenAI Gym 的 new_step_api）\n",
    "            else:\n",
    "                next_state, reward, terminated, info = env.step(action)  # 更新环境并返回新状态、奖励、终止状态和其他信息（使用 OpenAI Gym 的 old_step_api） \n",
    "            agent.update(state, action, reward, next_state, terminated)  # 更新 agent\n",
    "            if i_ep == 0 or i_ep == cfg.train_eps - 1:\n",
    "                if ep_step <= 10:\n",
    "                    print(f\"=================== episode-{i_ep}:step-{ep_step} Q_table的值 ===============\")\n",
    "                    print(f\"Q_table长度：{len(agent.Q_table)}\")\n",
    "                    # 打印Q_table(嵌套字典类型)\n",
    "                    # print(agent.Q_table)\n",
    "                    for key, value in agent.Q_table.items():\n",
    "                        print(f\"状态：{key}，动作价值函数Q值：{value}\")\n",
    "            state = next_state  # 更新状态 \n",
    "            ep_reward += reward  # 增加奖励 \n",
    "            if terminated:\n",
    "                break\n",
    "        steps.append(ep_step)\n",
    "        rewards.append(ep_reward)\n",
    "        if (i_ep + 1) <= 2:\n",
    "            print(f\"================================================================\")\n",
    "            print(f\"回合：{i_ep+1}/{cfg.train_eps}，奖励：{ep_reward:.2f}\")\n",
    "            # cliffwalking.py中关于Observations的注释：\n",
    "            # There are 3x12 + 1 possible states. In fact, the agent cannot be at the cliff, nor at the goal\n",
    "            print(f\"Q_table长度：{len(agent.Q_table)}\") \n",
    "            # 打印Q_table(嵌套字典类型)\n",
    "            # print(agent.Q_table)\n",
    "            for key, value in agent.Q_table.items():\n",
    "                print(f\"状态：{key}，动作价值函数Q值：{value}\")\n",
    "        if (i_ep + 1) % 10 == 0:\n",
    "            print(f\"================================================================\")\n",
    "            print(f\"回合：{i_ep+1}/{cfg.train_eps}，奖励：{ep_reward:.2f}\")\n",
    "    print(\"完成训练！\")\n",
    "    return {'rewards':rewards}\n",
    "\n",
    "def test(cfg, env, agent):\n",
    "    print(\"开始测试！\")\n",
    "    rewards = []  # 记录所有回合的奖励\n",
    "    steps = []\n",
    "    for i_ep in range(cfg.test_eps):\n",
    "        ep_reward = 0  # 一轮的累计奖励 \n",
    "        ep_step = 0\n",
    "        state = env.reset(seed = cfg.seed)  # 重置环境并获取初始状态 \n",
    "        for _ in range(cfg.max_steps):\n",
    "            if cfg.render:\n",
    "                env.render()\n",
    "            ep_step += 1\n",
    "            action = agent.predict_action(state)  # 预测动作 \n",
    "            next_state, reward, terminated, truncated , info = env.step(action)\n",
    "            state = next_state  # 更新状态 \n",
    "            ep_reward += reward  # 增加奖励\n",
    "            if terminated:\n",
    "                break\n",
    "        steps.append(ep_step)\n",
    "        rewards.append(ep_reward)\n",
    "        print(f\"回合：{i_ep+1}/{cfg.test_eps}，奖励：{ep_reward:.2f}\")\n",
    "    print(\"完成测试\")\n",
    "    env.close()\n",
    "    return {'rewards':rewards}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3定义环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import random\n",
    "def all_seed(env,seed = 1):\n",
    "    ''' 万能的seed函数\n",
    "    '''\n",
    "    env.reset(seed=seed)  # env config\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)  # config for CPU\n",
    "    torch.cuda.manual_seed(seed)  # config for GPU\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # config for python scripts\n",
    "    # config for cudnn\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "def env_agent_config(cfg):\n",
    "    env = gym.make(cfg.env_name)  # 创建环境\n",
    "    all_seed(env,seed=cfg.seed)\n",
    "    print(env.observation_space.shape)\n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    print(f\"状态空间维度：{n_states}，动作空间维度：{n_actions}\")\n",
    "    # 更新n_states和n_actions到cfg参数中\n",
    "    setattr(cfg, 'n_states', n_states)\n",
    "    setattr(cfg, 'n_actions', n_actions) \n",
    "    setattr(cfg, 'action_space', env.action_space) \n",
    "    agent = Qlearning(cfg)\n",
    "    return env, agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.设置参数\n",
    "在这里定义我们的通用参数以及Qlearning参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # pip install matplotlib==3.8.4\n",
    "import seaborn as sns  # pip install seaborn==0.13.2\n",
    "class Config:\n",
    "    def __init__(self) -> None:\n",
    "        ## 通用参数\n",
    "        self.env_name = \"CliffWalking-v0\"  # name of environment\n",
    "        self.new_step_api = True  # whether to use new step api of gym\n",
    "        self.wrapper = None  # wrapper of environment\n",
    "        self.render = False  # whether to render environment\n",
    "        self.render_mode = \"human\"  # 渲染模式, \"human\" 或者 \"rgb_array\"\n",
    "        self.algo_name = \"Qlearning\"  # name of algorithm\n",
    "        self.mode = \"train\"  # train or test\n",
    "        self.mp_backend = \"mp\"  # 多线程框架，ray或者mp(multiprocessing)，默认mp\n",
    "        self.seed = 1  # random seed\n",
    "        self.device = \"cuda\"  # device to use\n",
    "        self.train_eps = 500  # number of episodes for training\n",
    "        self.test_eps = 10  # number of episodes for testing\n",
    "        self.eval_eps = 10  # number of episodes for evaluation\n",
    "        self.eval_per_episode = 5  # evaluation per episode\n",
    "        self.max_steps = 1000  # max steps for each episode\n",
    "        self.load_checkpoint = False\n",
    "        self.load_path = \"tasks\"  # path to load model\n",
    "        self.show_fig = False  # show figure or not\n",
    "        self.save_fig = True  # save figure or not\n",
    "\n",
    "        ## Qlearing参数\n",
    "        self.epsilon_start = 0.95  # epsilon 初始值\n",
    "        self.epsilon_end = 0.01  # epsilon 终止值\n",
    "        self.epsilon_decay = 300  # epsilon 衰减率\n",
    "        self.gamma = 0.90  # 奖励折扣因子\n",
    "        self.lr = 0.1  # 学习率\n",
    "\n",
    "def smooth(data, weight=0.9):  \n",
    "    '''用于平滑曲线，类似于Tensorboard中的smooth曲线\n",
    "    '''\n",
    "    last = data[0] \n",
    "    smoothed = []\n",
    "    for point in data:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # 计算平滑值\n",
    "        smoothed.append(smoothed_val)                    \n",
    "        last = smoothed_val                                \n",
    "    return smoothed\n",
    "\n",
    "def plot_rewards(rewards, title=\"learning curve\"):\n",
    "    sns.set()\n",
    "    plt.figure()  # 创建一个图形实例，方便同时多画几个图\n",
    "    plt.title(f\"{title}\")\n",
    "    plt.xlim(0, len(rewards), 10)  # 设置x轴的范围\n",
    "    plt.xlabel('episodes')\n",
    "    plt.plot(rewards, label='rewards')\n",
    "    plt.plot(smooth(rewards), label='smoothed')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "状态空间维度：48，动作空间维度：4\n",
      "开始训练！\n",
      "=================== episode-0:step-1 Q_table的值 ===============\n",
      "Q_table长度：2\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[0. 0. 0. 0.]\n",
      "=================== episode-0:step-2 Q_table的值 ===============\n",
      "Q_table长度：3\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：25，动作价值函数Q值：[0. 0. 0. 0.]\n",
      "=================== episode-0:step-3 Q_table的值 ===============\n",
      "Q_table长度：3\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：25，动作价值函数Q值：[ 0.   0.   0.  -0.1]\n",
      "=================== episode-0:step-4 Q_table的值 ===============\n",
      "Q_table长度：3\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19  0.    0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.   0.   0.  -0.1]\n",
      "=================== episode-0:step-5 Q_table的值 ===============\n",
      "Q_table长度：4\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19  0.    0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[0. 0. 0. 0.]\n",
      "=================== episode-0:step-6 Q_table的值 ===============\n",
      "Q_table长度：5\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19  0.    0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：27，动作价值函数Q值：[0. 0. 0. 0.]\n",
      "=================== episode-0:step-7 Q_table的值 ===============\n",
      "Q_table长度：6\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19  0.    0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：27，动作价值函数Q值：[  0.   0. -10.   0.]\n",
      "状态：36，动作价值函数Q值：[0. 0. 0. 0.]\n",
      "=================== episode-0:step-8 Q_table的值 ===============\n",
      "Q_table长度：6\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19  0.    0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：27，动作价值函数Q值：[  0.   0. -10.   0.]\n",
      "状态：36，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "=================== episode-0:step-9 Q_table的值 ===============\n",
      "Q_table长度：6\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19 -0.1   0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：27，动作价值函数Q值：[  0.   0. -10.   0.]\n",
      "状态：36，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "=================== episode-0:step-10 Q_table的值 ===============\n",
      "Q_table长度：6\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[ 0.   -0.19 -0.1   0.  ]\n",
      "状态：25，动作价值函数Q值：[ 0.  -0.1  0.  -0.1]\n",
      "状态：26，动作价值函数Q值：[ 0.  -0.1  0.   0. ]\n",
      "状态：27，动作价值函数Q值：[  0.   0. -10.   0.]\n",
      "状态：36，动作价值函数Q值：[-0.1  0.  -0.1  0. ]\n",
      "================================================================\n",
      "回合：1/500，奖励：-3867.00\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[-0.1  0.   0.   0. ]\n",
      "状态：24，动作价值函数Q值：[-1.47033628 -1.42981858 -1.42891921 -1.44703171]\n",
      "状态：25，动作价值函数Q值：[ -1.1929328   -1.17291561 -41.22491788  -1.2036961 ]\n",
      "状态：26，动作价值函数Q值：[ -1.04673915  -1.02719628 -10.0267309   -1.02903567]\n",
      "状态：27，动作价值函数Q值：[ -0.91020306  -0.83557066 -19.13114889  -0.90148692]\n",
      "状态：36，动作价值函数Q值：[ -1.81170845 -69.00010354  -1.86143111  -1.82093062]\n",
      "状态：13，动作价值函数Q值：[-1.21682162 -1.14507339 -1.15133051 -1.19737794]\n",
      "状态：1，动作价值函数Q值：[-1.12659174 -1.18509351 -1.14419228 -1.1149762 ]\n",
      "状态：0，动作价值函数Q值：[-1.20866628 -1.18566019 -1.25260337 -1.22891398]\n",
      "状态：14，动作价值函数Q值：[-1.05245339 -0.98322887 -1.03060467 -1.05323407]\n",
      "状态：12，动作价值函数Q值：[-1.2909512  -1.33485347 -1.28281116 -1.28244233]\n",
      "状态：2，动作价值函数Q值：[-1.0500628  -1.08867064 -1.04897367 -1.05165168]\n",
      "状态：3，动作价值函数Q值：[-0.87953944 -0.85919606 -0.93709426 -0.94759832]\n",
      "状态：4，动作价值函数Q值：[-0.77255306 -0.78757405 -0.73661124 -0.75537168]\n",
      "状态：5，动作价值函数Q值：[-0.66923449 -0.70827606 -0.6508439  -0.64964564]\n",
      "状态：6，动作价值函数Q值：[-0.47941603 -0.55346491 -0.54814467 -0.52838882]\n",
      "状态：7，动作价值函数Q值：[-0.3940399  -0.4653361  -0.3860209  -0.42062852]\n",
      "状态：19，动作价值函数Q值：[-0.38757108 -0.385219   -0.37799461 -0.32055603]\n",
      "状态：18，动作价值函数Q值：[-0.49411092 -0.47270556 -0.45957026 -0.5455761 ]\n",
      "状态：30，动作价值函数Q值：[ -0.41772511  -0.36991    -19.28024459  -0.44403201]\n",
      "状态：31，动作价值函数Q值：[ -0.305029   -0.2881    -10.009      -0.3247622]\n",
      "状态：15，动作价值函数Q值：[-0.86751884 -0.91167463 -0.91439286 -0.86973362]\n",
      "状态：16，动作价值函数Q值：[-0.7698232  -0.77820395 -0.71455759 -0.75776297]\n",
      "状态：17，动作价值函数Q值：[-0.67743946 -0.62192335 -0.63469087 -0.66127319]\n",
      "状态：29，动作价值函数Q值：[ -0.60475031  -0.53566612 -10.06853248  -0.54513591]\n",
      "状态：28，动作价值函数Q值：[ -0.71801455  -0.6261409  -27.4169519   -0.69527706]\n",
      "状态：8，动作价值函数Q值：[-0.385219  -0.37639   -0.3772    -0.3131209]\n",
      "状态：9，动作价值函数Q值：[-0.29701   -0.28      -0.2962    -0.3137041]\n",
      "状态：10，动作价值函数Q值：[-0.199   -0.199   -0.19    -0.20791]\n",
      "状态：11，动作价值函数Q值：[-0.199 -0.199 -0.19  -0.199]\n",
      "状态：23，动作价值函数Q值：[-0.199 -0.19  -0.1   -0.1  ]\n",
      "状态：22，动作价值函数Q值：[-0.109 -0.109 -0.19  -0.19 ]\n",
      "状态：35，动作价值函数Q值：[-0.1 -0.1 -0.1 -0.1]\n",
      "状态：34，动作价值函数Q值：[ -0.109       -0.19       -10.11023108  -0.1       ]\n",
      "状态：33，动作价值函数Q值：[ -0.19        -0.199      -10.14893761  -0.1       ]\n",
      "状态：21，动作价值函数Q值：[-0.28977751 -0.199      -0.28       -0.19      ]\n",
      "状态：20，动作价值函数Q值：[-0.28891  -0.30349  -0.28     -0.305758]\n",
      "状态：32，动作价值函数Q值：[ -0.199       -0.19       -10.12274198  -0.20965223]\n",
      "================================================================\n",
      "回合：2/500，奖励：-472.00\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -0.1        -10.16305376   0.           0.        ]\n",
      "状态：24，动作价值函数Q值：[-1.60103582 -1.60779731 -1.66977345 -1.61723578]\n",
      "状态：25，动作价值函数Q值：[ -1.27669612  -1.32223556 -47.26995489  -1.32125702]\n",
      "状态：26，动作价值函数Q值：[ -1.13678604  -1.17162848 -10.0267309   -1.13349606]\n",
      "状态：27，动作价值函数Q值：[ -1.00541126  -1.05733061 -19.13114889  -1.00395144]\n",
      "状态：36，动作价值函数Q值：[ -2.02807086 -69.00010354  -2.02338863  -2.06385716]\n",
      "状态：13，动作价值函数Q值：[-1.30179788 -1.29281943 -1.24453011 -1.30081104]\n",
      "状态：1，动作价值函数Q值：[-1.30317256 -1.26108981 -1.3250734  -1.30772486]\n",
      "状态：0，动作价值函数Q值：[-1.38361382 -1.4172613  -1.34747985 -1.40345859]\n",
      "状态：14，动作价值函数Q值：[-1.14161569 -1.13873512 -1.12175072 -1.15153041]\n",
      "状态：12，动作价值函数Q值：[-1.44577873 -1.40913213 -1.38884596 -1.36961791]\n",
      "状态：2，动作价值函数Q值：[-1.13956218 -1.08867064 -1.13886737 -1.15558978]\n",
      "状态：3，动作价值函数Q值：[-0.97074404 -1.02158734 -1.02166086 -0.94759832]\n",
      "状态：4，动作价值函数Q值：[-0.86482753 -0.86739259 -0.91457262 -0.85899306]\n",
      "状态：5，动作价值函数Q值：[-0.76254215 -0.78678147 -0.74288169 -0.75097609]\n",
      "状态：6，动作价值函数Q值：[-0.57462187 -0.63999867 -0.64243205 -0.63401805]\n",
      "状态：7，动作价值函数Q值：[-0.4900995  -0.55267759 -0.48208852 -0.52837751]\n",
      "状态：19，动作价值函数Q值：[-0.48427756 -0.4740112  -0.46942375 -0.42986175]\n",
      "状态：18，动作价值函数Q值：[-0.58784727 -0.63839047 -0.55120849 -0.65439658]\n",
      "状态：30，动作价值函数Q值：[ -0.5184961   -0.5468383  -19.28024459  -0.54869104]\n",
      "状态：31，动作价值函数Q值：[ -0.40337614  -0.463951   -10.009       -0.43224886]\n",
      "状态：15，动作价值函数Q值：[-1.04699853 -0.98870584 -1.00470654 -0.97551467]\n",
      "状态：16，动作价值函数Q值：[-0.86237066 -0.93487788 -0.89665825 -0.86428203]\n",
      "状态：17，动作价值函数Q值：[-0.76992662 -0.78338966 -0.72660701 -0.76765678]\n",
      "状态：29，动作价值函数Q值：[ -0.70024838  -0.69514859 -10.06853248  -0.76049701]\n",
      "状态：28，动作价值函数Q值：[ -0.9113383   -0.8742793  -27.4169519   -0.91458844]\n",
      "状态：8，动作价值函数Q值：[-0.385219   -0.463951   -0.3772     -0.41655069]\n",
      "状态：9，动作价值函数Q值：[-0.29701   -0.36991   -0.39178   -0.3137041]\n",
      "状态：10，动作价值函数Q值：[-0.29701  -0.2962   -0.28081  -0.313777]\n",
      "状态：11，动作价值函数Q值：[-0.29701   -0.29701   -0.2881    -0.2978119]\n",
      "状态：23，动作价值函数Q值：[-0.29701 -0.2881  -0.2881  -0.2071 ]\n",
      "状态：22，动作价值函数Q值：[-0.2152    -0.3043    -0.28      -0.2970019]\n",
      "状态：35，动作价值函数Q值：[-0.199 -0.199 -0.19  -0.1  ]\n",
      "状态：34，动作价值函数Q值：[ -0.2152      -0.19       -10.11023108  -0.20791   ]\n",
      "状态：33，动作价值函数Q值：[ -0.2881      -0.28891    -19.30528877  -0.20791   ]\n",
      "状态：21，动作价值函数Q值：[-0.28977751 -0.378658   -0.36991    -0.2970019 ]\n",
      "状态：20，动作价值函数Q值：[-0.38819988 -0.391051   -0.3708687  -0.305758  ]\n",
      "状态：32，动作价值函数Q值：[ -0.3043      -0.3691     -10.12274198  -0.31613961]\n",
      "================================================================\n",
      "回合：10/500，奖励：-155.00\n",
      "================================================================\n",
      "回合：20/500，奖励：-126.00\n",
      "================================================================\n",
      "回合：30/500，奖励：-78.00\n",
      "================================================================\n",
      "回合：40/500，奖励：-48.00\n",
      "================================================================\n",
      "回合：50/500，奖励：-33.00\n",
      "================================================================\n",
      "回合：60/500，奖励：-32.00\n",
      "================================================================\n",
      "回合：70/500，奖励：-88.00\n",
      "================================================================\n",
      "回合：80/500，奖励：-29.00\n",
      "================================================================\n",
      "回合：90/500，奖励：-63.00\n",
      "================================================================\n",
      "回合：100/500，奖励：-54.00\n",
      "================================================================\n",
      "回合：110/500，奖励：-33.00\n",
      "================================================================\n",
      "回合：120/500，奖励：-28.00\n",
      "================================================================\n",
      "回合：130/500，奖励：-33.00\n",
      "================================================================\n",
      "回合：140/500，奖励：-35.00\n",
      "================================================================\n",
      "回合：150/500，奖励：-48.00\n",
      "================================================================\n",
      "回合：160/500，奖励：-25.00\n",
      "================================================================\n",
      "回合：170/500，奖励：-23.00\n",
      "================================================================\n",
      "回合：180/500，奖励：-20.00\n",
      "================================================================\n",
      "回合：190/500，奖励：-29.00\n",
      "================================================================\n",
      "回合：200/500，奖励：-19.00\n",
      "================================================================\n",
      "回合：210/500，奖励：-19.00\n",
      "================================================================\n",
      "回合：220/500，奖励：-20.00\n",
      "================================================================\n",
      "回合：230/500，奖励：-19.00\n",
      "================================================================\n",
      "回合：240/500，奖励：-17.00\n",
      "================================================================\n",
      "回合：250/500，奖励：-26.00\n",
      "================================================================\n",
      "回合：260/500，奖励：-25.00\n",
      "================================================================\n",
      "回合：270/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：280/500，奖励：-23.00\n",
      "================================================================\n",
      "回合：290/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：300/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：310/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：320/500，奖励：-14.00\n",
      "================================================================\n",
      "回合：330/500，奖励：-14.00\n",
      "================================================================\n",
      "回合：340/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：350/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：360/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：370/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：380/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：390/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：400/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：410/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：420/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：430/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：440/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：450/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：460/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：470/500，奖励：-17.00\n",
      "================================================================\n",
      "回合：480/500，奖励：-13.00\n",
      "================================================================\n",
      "回合：490/500，奖励：-13.00\n",
      "=================== episode-499:step-1 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-2 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-3 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-4 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-5 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-6 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-7 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-8 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-9 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "=================== episode-499:step-10 Q_table的值 ===============\n",
      "Q_table长度：38\n",
      "状态：(36, {'prob': 1})，动作价值函数Q值：[ -7.45813411 -36.29099219  -7.46569236  -7.49695065]\n",
      "状态：24，动作价值函数Q值：[-7.18475962 -7.17570462 -7.23455916 -7.1920924 ]\n",
      "状态：25，动作价值函数Q值：[ -6.87594697  -6.86189404 -53.17351705  -6.89718689]\n",
      "状态：26，动作价值函数Q值：[ -6.5367016   -6.5132156  -10.0267309   -6.60022075]\n",
      "状态：27，动作价值函数Q值：[ -6.14064085  -6.12579511 -34.85268696  -6.14371702]\n",
      "状态：36，动作价值函数Q值：[ -7.42880251 -72.76360766  -7.43564994  -7.4493367 ]\n",
      "状态：13，动作价值函数Q值：[-6.73762082 -6.74282198 -6.75676623 -6.75805443]\n",
      "状态：1，动作价值函数Q值：[-6.65262522 -6.65115018 -6.65696413 -6.67558672]\n",
      "状态：0，动作价值函数Q值：[-6.81426666 -6.82052814 -6.82700977 -6.82033046]\n",
      "状态：14，动作价值函数Q值：[-6.48172773 -6.46800822 -6.46907143 -6.5206282 ]\n",
      "状态：12，动作价值函数Q值：[-6.95536076 -6.96079324 -6.99492581 -6.95874837]\n",
      "状态：2，动作价值函数Q值：[-6.44522002 -6.42569919 -6.41572101 -6.44271319]\n",
      "状态：3，动作价值函数Q值：[-6.15723784 -6.14528426 -6.15714518 -6.17034848]\n",
      "状态：4，动作价值函数Q值：[-5.82591329 -5.82278088 -5.84372311 -5.86073558]\n",
      "状态：5，动作价值函数Q值：[-5.47465925 -5.47807663 -5.46957523 -5.49278207]\n",
      "状态：6，动作价值函数Q值：[-5.09359677 -5.08515987 -5.08886512 -5.13281921]\n",
      "状态：7，动作价值函数Q值：[-4.69094457 -4.65947868 -4.69205986 -4.68332221]\n",
      "状态：19，动作价值函数Q值：[-4.5486728  -4.49898665 -4.51390077 -4.59008178]\n",
      "状态：18，动作价值函数Q值：[-4.98193138 -4.98506823 -4.98145263 -5.04337684]\n",
      "状态：30，动作价值函数Q值：[ -4.77870575  -4.68559    -35.88041014  -4.8524551 ]\n",
      "状态：31，动作价值函数Q值：[ -4.19738587  -4.0951     -10.009       -4.35405951]\n",
      "状态：15，动作价值函数Q值：[-6.15096868 -6.15491082 -6.16764717 -6.20623692]\n",
      "状态：16，动作价值函数Q值：[-5.80567062 -5.80519842 -5.7993974  -5.84615354]\n",
      "状态：17，动作价值函数Q值：[-5.45906766 -5.41143648 -5.4304921  -5.44790332]\n",
      "状态：29，动作价值函数Q值：[ -5.31270609  -5.217031   -10.06853248  -5.28495294]\n",
      "状态：28，动作价值函数Q值：[ -5.70550866  -5.6953279  -42.45837597  -5.72011792]\n",
      "状态：8，动作价值函数Q值：[-4.18299916 -4.19004329 -4.18147679 -4.27625795]\n",
      "状态：9，动作价值函数Q值：[-3.69611583 -3.68020159 -3.70319933 -3.68127315]\n",
      "状态：10，动作价值函数Q值：[-3.17445405 -3.14732603 -3.1525888  -3.14017341]\n",
      "状态：11，动作价值函数Q值：[-2.60299627 -2.60079515 -2.60867434 -2.63491042]\n",
      "状态：23，动作价值函数Q值：[-1.92087087 -1.97633294 -1.89873926 -1.92215294]\n",
      "状态：22，动作价值函数Q值：[-2.68352668 -2.67354674 -2.67317359 -2.80740525]\n",
      "状态：35，动作价值函数Q值：[-1.00275026 -1.20875953 -1.         -1.37995472]\n",
      "状态：34，动作价值函数Q值：[ -1.91700068  -1.9        -19.73840856  -2.00672819]\n",
      "状态：33，动作价值函数Q值：[ -2.98162883  -2.71       -27.99820184  -2.82760371]\n",
      "状态：21，动作价值函数Q值：[-3.41224318 -3.36022797 -3.36430274 -3.38261264]\n",
      "状态：20，动作价值函数Q值：[-4.00771654 -3.95673022 -3.95817959 -4.04083621]\n",
      "状态：32，动作价值函数Q值：[ -3.60163022  -3.439      -10.12274198  -3.51760162]\n",
      "================================================================\n",
      "回合：500/500，奖励：-13.00\n",
      "完成训练！\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_AxesBase.set_xlim() takes from 1 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m env, agent \u001b[38;5;241m=\u001b[39m env_agent_config(cfg)\n\u001b[0;32m      5\u001b[0m res_dic \u001b[38;5;241m=\u001b[39m train(cfg, env, agent)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplot_rewards\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining curve on \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m of \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 测试\u001b[39;00m\n\u001b[0;32m      9\u001b[0m res_dic \u001b[38;5;241m=\u001b[39m test(cfg, env, agent)\n",
      "Cell \u001b[1;32mIn[4], line 48\u001b[0m, in \u001b[0;36mplot_rewards\u001b[1;34m(rewards, title)\u001b[0m\n\u001b[0;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()  \u001b[38;5;66;03m# 创建一个图形实例，方便同时多画几个图\u001b[39;00m\n\u001b[0;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 设置x轴的范围\u001b[39;00m\n\u001b[0;32m     49\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisodes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(rewards, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\EDA\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:1961\u001b[0m, in \u001b[0;36mxlim\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_xlim()\n\u001b[1;32m-> 1961\u001b[0m ret \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mset_xlim(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mTypeError\u001b[0m: _AxesBase.set_xlim() takes from 1 to 3 positional arguments but 4 were given"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取参数\n",
    "cfg = Config() \n",
    "# 训练\n",
    "env, agent = env_agent_config(cfg)\n",
    "res_dic = train(cfg, env, agent)\n",
    "plot_rewards(res_dic['rewards'], title=f\"training curve on {cfg.device} of {cfg.algo_name} for {cfg.env_name}\")  \n",
    "\n",
    "# 测试\n",
    "res_dic = test(cfg, env, agent)\n",
    "plot_rewards(res_dic['rewards'], title=f\"testing curve on {cfg.device} of {cfg.algo_name} for {cfg.env_name}\")  # 画出结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
